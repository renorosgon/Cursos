---
title: "Flujo para multiples modelos"
subtitle: "Economía aplicada y ciencia de datos para el bien público"
author: "Mtro. René Rosado González"
output: 
  html_document:
    theme: paper
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introducción

Reaven y Miller (1979) examinaron la relación entre las medidas de química sanguínea de la tolerancia a la glucosa y la insulina en 145 adultos no obesos. Usaron el sistema PRIM9 en el Centro Acelerador Lineal de Stanford para visualizar los datos en 3D y descubrieron un patrón peculiar que parecía una gran mancha con dos alas en diferentes direcciones.

Después de un análisis adicional, los sujetos se clasificaron como diabéticos subclínicos (químicos), diabéticos manifiestos y normales. Este estudio influyó en la definición de las etapas de desarrollo de la diabetes tipo 2. La diabetes manifiesta es la etapa más avanzada, caracterizada por una concentración elevada de glucosa en sangre en ayunas y síntomas clásicos. Precediendo a la diabetes manifiesta está la etapa diabética latente o química, sin síntomas de diabetes pero con anormalidad demostrable de tolerancia a la glucosa oral o intravenosa.

A continuación entrenarás un conjunto de modelos para realizar la mejor clasificación con base en la información del estudio.
### Librerías
Carga las librerías de `tidyverse`, `tidymodels` y `heplots`. Puedes utilizar el siguiente código de referencia

```{r librerías, message=FALSE, warning=FALSE}
# Instala - Carga tidyverse                                                       
if(require(tidyverse) == FALSE){                                                
  install.packages('tidyverse')                                                 
  library(tidyverse)                                                            
}else{                                                                          
  library(tidyverse)                                                            
}

# Instala - Carga tidymodels                                                  
if(require(tidymodels) == FALSE){                                                
  install.packages('tidymodels')                                                 
  library(tidymodels)                                                            
}else{                                                                          
  library(tidymodels)                                                            
} 

# Instala - Carga heplots                                                  
if(require(heplots) == FALSE){                                                
  install.packages('heplots')                                                 
  library(heplots)                                                            
}else{                                                                          
  library(heplots)                                                            
}                                                
```

### Los datos
Carga los datos y explora su contenido.
```{r datos.0, message=FALSE, warning=FALSE}
# Carga tus datos
diabetes = heplots::Diabetes

# Revisa la definición de cada variable
?heplots::Diabetes

# Explora los datos para conocer su estructura
glimpse(diabetes)
summary(diabetes)
```


Realiza un análisis exploratorio de datos. Puedes apoyarte en gráficos, estadísticos y correlaciones. Te recomiendo replicar la gráfica de Raven y Miller usando las variables `glutest` e `instest`, coloreando por la variable `group`. 

```{r datos.01, message=FALSE, warning=FALSE}
# Utiliza los datos
obs_graph = diabetes %>% 
  # Crea un gráfico de dispersión
  ggplot() +
  # Agrega la prueba de insulina en el eje x, y la prueba de glucosa en el eje y. Colorea por grupo
  geom_point(aes(x=instest, y = glutest, col = group)) +
  # Modifica las etiquetas para hacerlas informativas
  labs(x = 'Insuline test', y = 'Glucose test', col = 'Group') + 
  # Selecciona un tema
  theme_bw()

# Visualiza la gráfica
obs_graph
```

Una vez realizado tu análisis exploratorio de datos, comenzaremos a prepararar los insumos de nuestro flujo de trabajo. Comienza por separar los datos en un conjunto de prueba y uno de entrenaniento. Recuerda que nuestra variable a predecir es `group`

```{r grafica.1, message=FALSE, warning=FALSE}
# Separa en conjunto de prueba y entrenamiento
set.seed(210)
datos_split = initial_split(diabetes, strata = group)
datos_train = training(datos_split)
datos_test  = testing(datos_split)

# Dado que tenemos pocos datos, utilizaremos muestras bootstrap.
datos_cv = bootstraps(datos_train)
```

Define un objeto para construir un modelo con con cada uno de los algoritmos que podrían servir para este problema.

```{r grafica.2, message=FALSE, warning=FALSE}
# Define k-vecinos cercanos
modelo_knn = nearest_neighbor() %>%
  # Fija el motor
  set_engine('kknn') %>%
  # Fija el método de classificación
  set_mode('classification') %>% 
  # Fija los hyperparametros a optimizar
  set_args(
    # Numero de vecino
    neighbors   = tune(), 
    # Funcion de ponderacion
    weight_func = tune(),
    # Tipo de distancia
    dist_power  = tune()
  )

# Define regresion logistica multinomial (con regularizacion)
modelo_glmnet =  multinom_reg() %>% 
  # Define el motor
  set_engine('glmnet') %>% 
  # Define el modo
  set_mode('classification') %>% 
  # Define los hyperparametros
  set_args(
    # Penalizacion
    penalty = tune(),
    # Combinacion ridge-lasso
    mixture = tune()
    )

# Define un arbol aleatorio
modelo_arbol = decision_tree() %>%
  # Fija el motor
  set_engine('rpart')%>%
  # Fija el método de classificación
  set_mode('classification') %>% 
  # Fija los hyperparametros a optimizar
  set_args(
    # Costo de complejidad
    cost_complexity = tune(), 
    # Profundidad
    tree_depth = tune(), 
    # Minimo de observaciones
    min_n = tune()
    )

# Define un bosque aleatorio
modelo_bosque = rand_forest() %>% 
  # Fija el motor
  set_engine("ranger", importance = "permutation") %>% 
  # Fijo el modo
  set_mode("classification") %>% 
  # Fija los argumentos
  set_args( 
    # Número de predictores por muestra
    mtry = tune(),
    # Numero de árboles
    trees = tune(),
    # Minimo de observaciones
    min_n = tune()
    )

# Define xgboost
modelo_xgboots = boost_tree()  %>%
  # Fija el motor
  set_engine('xgboost')%>%
  # Fija el modo
  set_mode("classification") %>% 
  # Fija argumentos
  set_args(
    mtry = tune(),
    trees = tune(),
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    sample_size = tune(),
    stop_iter = tune()
  )
```

Define una receta que te permita preprocesar los datos. En este caso queremos classificar a las personas por grupos en función de las características de su química sanguinea. Agrega almenos un paso de preprocesamiento. Puedes buscar todas las opciones disponibles de la paquetería `recipe`.

```{r grafica.3, message=FALSE, warning=FALSE}
# Define una recera
receta = recipe(
  # Declara la fórmula a utilizas
  formula = group ~ .,
  # Declara los datos a usar
  data = datos_train
  ) %>%
  # Define un paso adicional
  step_normalize(all_numeric_predictors())
```

Ahora construiremos nuestro flujo de trabajo para ajustar y calibrar nuestros modelos de forma simultanea. Utiliza el siguiente código de referencia y completa los espacios en blanco 

```{r grafica.4, message=FALSE, warning=FALSE}
# Define un conjunto de flujos de trabajo
diabetes_workflow = workflow_set(
  # Agrega una lista de pasos de preprocesamiento (en este caso solo tenemos 1 receta)
  preproc = list(receta = receta),
  # Agrega una lista de modelos
  models = list(
    # Agrega el modelo de knn
    k_vecinos = modelo_knn, 
    # Agrega el modelo de glmnet
    glmnet = modelo_glmnet,
    # Agrega el modelo de arbol aleatorio
    arbol = modelo_arbol, 
    # Agrega el modelo de bosque aleatorio
    bosque = modelo_bosque,
    # Agrega el modelo de xgboost
    xgboost = modelo_xgboots)
) %>% 
  # Aplicaremos estos pasos a cada uno de los modelos
  workflow_map(
    # Agrega las muestras de validación
    resamples = datos_cv,
    # Define un numero de combinaciones para probar (puedes comenzar con 100)
    grid = 10,
    # Te recomiendo dejar verbose=TRUE para que puedas monitorear el avanza
    verbose = TRUE
  )

# Al final obtienes esto
diabetes_workflow
```

Podemos analizar los resultados obtenidos con las siguientes funciones
```{r grafica.5, message=FALSE, warning=FALSE}
# Ordena de mejor a peor modelo
rank_results(diabetes_workflow, rank_metric = "roc_auc")

# Podemos ver gráficamente el ranking 
autoplot(diabetes_workflow, metric = "roc_auc")
```

¿Qué tipo de algoritmos parecen funcionar mejor para este problema? ¿por qué?

Podemos ajustar el modelo final con base en los resultados anteriores. Para llamar al mejor modelo basta con llamar el nombre con el que aparece en la columna `wflow_id`.

```{r grafica.7, message=FALSE, warning=FALSE}
# Selecciona el mejor modelo
mejor_modelo = diabetes_workflow %>% 
  # Extrae el conjunto de resultados del algoritmo con mejor desempeño
  extract_workflow_set_result('receta_bosque') %>% 
  # Selecciona el mejor modelo con base en la metrica roc_auc
  select_best('roc_auc') 

# Finaliza el flujo de trabajo 
modelo_diabetes = diabetes_workflow %>% 
  # Extrae el flujo de trabjao
  extract_workflow('receta_bosque')  %>%  
  # Finaliza el flujo con el mejor modelo
  finalize_workflow(mejor_modelo) %>% 
  # Realiza el ultimo ajuste
  last_fit(datos_split)
```

Revisa las métricas de predicción en el conjunto de prueba utilizando el método `collect_metrics`
```{r grafica.8, message=FALSE, warning=FALSE}
modelo_diabetes %>% 
  collect_metrics()
```

Puedes realizar predicciones sobre conjuntos de datos nuevos, o viejos, extrayendo el flujo de trabajo del modelo final. Para ello, basta usar la función `extract_workflow` y aplicar los métodos de `predict` o `augment` en el conjunto de datos nuevo.
```{r grafica.9, message=FALSE, warning=FALSE}
# Genera una predicción
diabetes_pred = modelo_diabetes %>% 
  # Extrae el fjulo de trabajo
  extract_workflow() %>% 
  # Aplica el método agument en el conjunto de datos original
  augment(diabetes)

# Calcula la matriz de confusión
diabetes_pred %>% 
  conf_mat(truth = group, estimate = .pred_class)
```

Por último realiza el gráfico de Reaven y Miller, solo que en esta ocasión colorealo con la probabilidad de pertenecer a una clase.
```{r grafica.10, message=FALSE, warning=FALSE}
# Utiliza el tibble con predicciones
pred_graph = diabetes_pred %>% 
  # Reestructura el tibble
  gather(clase_pred, probability, -c(relwt:.pred_class)) %>% 
  # Remueve el prefico .pred_ y remplaza el guión bajo por un espacio
  mutate(clase_pred = str_replace(str_remove(clase_pred, '.pred_'),'_',' ')) %>% 
  # Realiza el gráfico de Reaven y Miller coloreando por probabilidad
  ggplot(aes(x=instest, y = glutest, col = probability)) +
  # Reliza un diagrama de dispersión
  geom_point() +
  # Separa por clase predicha
  facet_wrap(~clase_pred) +
  # Modifica las etiquetas
  labs(x = 'Insuline test', y = 'Glucose test', col = 'Probability') + 
  # Selecciona un tema
  theme_bw() 

# Compara el gráfico original con el estimado. Te sugiero utilizar la librería de pathcwork
library(patchwork)

pred_graph/obs_graph
```


