---
title: "K Nearest Neighbors Classifier"
author: "MDS. René Rosado González"
output: 
  html_document:
    theme: paper
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

You will work with the `CigarettesB` dataset from the `AER` package. Fill in the blanks in order to build a k-nearest neighbor regression model.

## Libraries
Load, and install if necessary, the `tidyverse` and `tidymodels` libraries. You will need to have installed the `kknn` and the `AER` package as well.

```{r libraries, warning = FALSE, message = FALSE, eval = FALSE}
# Install - load tidyverse                                                       
if(require(___) == FALSE){                                                
  install.packages('___')                                                 
  library(___)                                                            
}else{                                                                          
  library(___)                                                            
}
# Install - load tidymodels                                                       
if(require(___) == FALSE){                                                
  install.packages('___')                                                 
  library(___)                                                            
}else{                                                                          
  library(___)                                                            
}
# Install - kknn                                        
if(require(___) == FALSE){                                                
  install.packages('___')                                                 
  library(___)                                                            
}

# Install - AER                                       
if(require(___) == FALSE){                                                
  install.packages('___')                                                 
  library(___)                                                            
}
```

## Dataset
Load the  `CigarettesB` dataset from the `AER` package. You can read further details about the data using `?CigarettesB`.
```{r data, warning = FALSE, message = FALSE, eval = FALSE}
# Load the Teachingcigarettes dataset from the AER package
data(___, package = ___) 
```

## Exploratory Data Analysis (EDA)
Perform an exploratory data analysis using the `glimpse` and `summary` functions.
```{r glimpse, warning = FALSE, message = FALSE, eval = FALSE}
## Tidyway
glimpse(___)
```

```{r summary, warning = FALSE, message = FALSE, eval = FALSE}
# Summary
summary(___)
```
Use the `ggpairs` function from the `GGally` package to create a pairplot with the numeric variables.

```{r ggplot, warning = FALSE, message = FALSE, eval = FALSE}
# Install - GGally                                       
if(require(___) == FALSE){                                                
  install.packages(___)                                                 
}

# Pairplot
GGally::ggpairs(CigarettesB)
```

## KNN Regression
Create a model specification for the kkn using the `tidymodels` framework. 
```{r model, warning = FALSE, message = FALSE, eval = FALSE}
knn_model = ___() %>% 
  # Set the engine
  set_engine(___) %>% 
  # Set the mode
  set_mode(___) %>% 
  # Set hyperparameters to tune
  set_args(
    neighbors = tune(),
    dist_power = tune(),
    weight_func = tune()
    )
```

Make an initial data split with 75% of the observations in the training set. To get consistent results lets set a random seed of `123`.
```{r splitting, warning = FALSE, message = FALSE, eval = FALSE}
# Data splitting for samples
set.seed(___)
cigarettes_split = initial_split(
  # Data to split
  data = ___,
  # Proportions
  prop = ___,
  # Variable of interest
  strata = ___
)

# Get training and testing samples
cigarettes_training = ___(___)
cigarettes_testing = ___(___)
```

Create 3 cross validation folds from the training set.
```{r folds, warning = FALSE, message = FALSE, eval = FALSE}
# Create cross-validation folds
set.seed(___)
cigarettes_folds = vfold_cv(___, v = ___)
```

Create the following recipe to predict the `packs` in function of all other variables.
```{r recipe, warning = FALSE, message = FALSE, eval = FALSE}
# Create a recipe
recipe = recipe(
  # Set a formula
  formula = ___, 
  # Set input data
  data = ___
) 
```

Make a workflow object with the recipe and model you just created.
```{r workflow, warning = FALSE, message = FALSE, eval = FALSE}
# Create a workflow
knn_workflow = workflow() %>% 
  # Add your recipe
  add_recipe(___) %>% 
  # Add your model
  add_model(___)
```

Perform hyperparameter tuning on the workflow you just created using a `grid` of size 100.
```{r tuning, warning = FALSE, message = FALSE, eval = FALSE}
# Get parameters to tune
knn_parameters = knn_workflow %>% 
  extract_parameter_set_dials() 

# Create a tune grid
set.seed(123)
knn_tuning = tune_grid(
  object = ___,
  resamples = ___,
  param_info = ___,
  metrics = metric_set(___),
  control = control_grid(verbose = TRUE),
  grid = ___
  )
```
Collect the tuning metrics and select the best model based on the `rmse` metric.
```{r best_model, warning = FALSE, message = FALSE, eval = FALSE}
# Collegt metrics
tuning_metrics = ___ %>%
  collect_metrics() %>% 
  # Arrange form higher mean to lower mean
  arrange(___)

# Select the best model
best_knn = knn_tuning %>%
  select_best(___)

# Print the best model
print(___)
```
Finalize your workflow and make the last fit to collect the performance of the model with the testing sample.
```{r finalize, warning = FALSE, message = FALSE, eval = FALSE}
# Finalize the workflow with the best model
final_knn = knn_workflow %>% 
  finalize_workflow(___)

# Make the last fit
results_knn = final_knn %>% 
  last_fit(
    split = ___,
    metrics = metric_set(___)
    )

# Collect testing metrics
metrics_knn = ___ %>% 
  collect_metrics()

print(___)
```

Plot the regression plot of the model you just trained
```{r regression_plot, warning = FALSE, message = FALSE, eval = FALSE}
# Extract the trained model
knn_trained = results_knn %>% 
  extract_fit_parsnip() 

# Add predictions
predictions_tb = augment(___, ___) 

# Regression plot (observed vs predicted)
ggplot(predictions_tb, aes(x = ___, y = ___)) + 
  # Create a scatter plot
  geom_point(alpha = 0.75) + 
  # Add 45 degree, red, dashhed curve
  geom_abline(linetype = ___) + 
  # Make equal axis coordinates
  coord_obs_pred() +
  # Add proper labels
  labs(
    x = ___,
    y = ___,
    title = ___,
    subtitle = ___,
    caption = ___
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = ___,
    # Delete legend background
    legend.background = ___,
    # Delete legend box background
    legend.box.background = ___,
    # Make legend key fill transparent
    legend.key = ___,
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

As you can see, there are some observations with a better fit (a lower prediction error). Let see if we can understand why it is so. Create the following plots and compare them to see what's happening.
```{r log_income_plot, warning = FALSE, message = FALSE, eval = FALSE}
# Create a ggplot with the prediction_tb. Use the income variable in the x axis
ggplot(predictions_tb, aes(x = income)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = income, xend = income, 
      # Set pack as y and .pred as yend
      y = packs, yend = .pred
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    ) + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = packs, col = 'Observed'), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = .pred, col = 'Predicted'), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  labs(
    x = 'Income (log)',
    y = 'Packs (log)',
    title = 'KNN Results',
    subtitle = 'Consumed packs in function of income (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

```{r training_testing, warning = FALSE, message = FALSE, eval = FALSE}
# Plot decision boundatires
training = augment(knn_trained, cigarettes_training) %>% 
  mutate(set = 'Training Set')
testing = augment(knn_trained, cigarettes_testing) %>% 
  mutate(set = 'Testing Set')

predictions_tb = bind_rows(training, testing)

ggplot(predictions_tb, aes(x = income)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = ___, xend = ___, 
      # Set pack as y and .pred as yend
      y = ___, yend = ___
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    ) + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = ___, shape = ___, col = ___), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = ___, shape = ___, col = ___), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  # Modify shape
  scale_shape_manual(values = c(20,4)) +
  # Add proper labels
  labs(
    x = ___,
    y = ___,
    title = ___,
    subtitle = ___,
    caption = ___
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = ___,
    # Delete legend background
    legend.background = ___,
    # Delete legend box background
    legend.box.background = ___,
    # Make legend key fill transparent
    legend.key =___,
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = ___,
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = ___,
    # Modify the height of the legend key to 0.5 cm
    legend.spacing.y = ___,
  ) 

```


