---
title: "K Nearest Neighbors Classifier"
author: "MDS. René Rosado González"
output: 
  html_document:
    theme: paper
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

You will work with the `CigarettesB` dataset from the `AER` package. Fill in the blanks in order to build a k-nearest neighbor regression model.

## Libraries
Load, and install if necessary, the `tidyverse` and `tidymodels` libraries. You will need to have installed the `kknn` and the `AER` package as well.

```{r libraries, warning = FALSE, message = FALSE}
# Install - load tidyverse                                                       
if(require(tidyverse) == FALSE){                                                
  install.packages('tidyverse')                                                 
  library(tidyverse)                                                            
}else{                                                                          
  library(tidyverse)                                                            
}
# Install - load tidymodels                                                       
if(require(tidymodels) == FALSE){                                                
  install.packages('tidymodels')                                                 
  library(tidymodels)                                                            
}else{                                                                          
  library(tidymodels)                                                            
}
# Install - kknn                                        
if(require(kknn) == FALSE){                                                
  install.packages('kknn')                                                 
}

# Install - AER                                       
if(require(AER) == FALSE){                                                
  install.packages('AER')                                                 
}
```

## Dataset
Load the  `CigarettesB` dataset from the `AER` package. You can read further details about the data using `?CigarettesB`.
```{r data, warning = FALSE, message = FALSE}
# Load the Teachingcigarettes dataset from the AER package
data('CigarettesB', package = 'AER') 
```

## Exploratory Data Analysis (EDA)
Perform an exploratory data analysis using the `glimpse` and `summary` functions.
```{r glimpse, warning = FALSE, message = FALSE}
## Tidyway
glimpse(CigarettesB)
```

```{r summary, warning = FALSE, message = FALSE}
# Summary
summary(CigarettesB)
```
Use the `ggpairs` function from the `GGally` package to create a pairplot with the numeric variables.

```{r ggplot, warning = FALSE, message = FALSE}
# Install - GGally                                       
if(require(GGally) == FALSE){                                                
  install.packages('GGally')                                                 
}

# Pairplot
GGally::ggpairs(CigarettesB)
```

## KNN Regression
Create a model specification for the kkn using the `tidymodels` framework. 
```{r model, warning = FALSE, message = FALSE}
knn_model = nearest_neighbor() %>% 
  # Set the engine
  set_engine("kknn") %>% 
  # Set the mode
  set_mode('regression') %>% 
  # Set hyperparameters to tune
  set_args(
    neighbors = tune(),
    dist_power = tune(),
    weight_func = tune()
    )
```

Make an initial data split with 75% of the observations in the training set. To get consistent results lets set a random seed of `123`.
```{r splitting, warning = FALSE, message = FALSE}
# Data splitting for samples
set.seed(123)
cigarettes_split = initial_split(
  # Data to split
  data = CigarettesB,
  # Proportions
  prop = 0.75,
  # Variable of interest
  strata = packs
)

# Get training and testing samples
cigarettes_training = training(cigarettes_split)
cigarettes_testing = testing(cigarettes_split)
```

Create 3 cross validation folds from the training set.
```{r folds, warning = FALSE, message = FALSE}
# Create cross-validation folds
set.seed(123)
cigarettes_folds = vfold_cv(cigarettes_training, v = 3)
```

Create the following recipe to predict the `packs` in function of all other variables.
```{r recipe, warning = FALSE, message = FALSE}
# Create a recipe
recipe = recipe(
  # Set a formula
  formula = packs ~ ., 
  # Set input data
  data = cigarettes_training
) 
```

Make a workflow object with the recipe and model you just created.
```{r workflow, warning = FALSE, message = FALSE}
# Create a workflow
knn_workflow = workflow() %>% 
  # Add your recipe
  add_recipe(recipe) %>% 
  # Add your model
  add_model(knn_model)
```

Perform hyperparameter tuning on the workflow you just created using a `grid` of size 100.
```{r tuning, warning = FALSE, message = FALSE}
# Get parameters to tune
knn_parameters = knn_workflow %>% 
  extract_parameter_set_dials() 

# Create a tune grid
set.seed(123)
knn_tuning = tune_grid(
  object = knn_workflow,
  resamples = cigarettes_folds,
  param_info = knn_parameters,
  metrics = metric_set(yardstick::rmse),
  control = control_grid(verbose = TRUE),
  grid = 100
  )
```
Collect the tuning metrics and select the best model based on the `rmse` metric.
```{r best_model, warning = FALSE, message = FALSE}
# Collegt metrics
tuning_metrics = knn_tuning %>%
  collect_metrics() %>% 
  # Arrange form higher mean to lower mean
  arrange(mean)

# Select the best model
best_knn = knn_tuning %>%
  select_best("rmse")

# Print the best model
print(best_knn)
```
Finalize your workflow and make the last fit to collect the performance of the model with the testing sample.
```{r finalize, warning = FALSE, message = FALSE}
# Finalize the workflow with the best model
final_knn = knn_workflow %>% 
  finalize_workflow(best_knn)

# Make the last fit
results_knn = final_knn %>% 
  last_fit(
    split = cigarettes_split,
    metrics = metric_set(yardstick::rmse)
    )

# Collect testing metrics
metrics_knn = results_knn %>% 
  collect_metrics()

print(metrics_knn)
```

Plot the regression plot of the model you just trained
```{r regression_plot, warning = FALSE, message = FALSE}
# Extract the trained model
knn_trained = results_knn %>% 
  extract_fit_parsnip() 

# Add predictions
predictions_tb = augment(knn_trained, CigarettesB) 

# Regression plot (observed vs predicted)
ggplot(predictions_tb, aes(x = packs, y = .pred)) + 
  # Create a scatter plot
  geom_point(alpha = 0.75) + 
  # Add 45 degree, red, dashhed curve
  geom_abline(linetype = 'dashed') + 
  # Make equal axis coordinates
  coord_obs_pred() +
  # Add proper labels
  labs(
    x = 'Observed',
    y = 'Predicted',
    title = 'KNN Results',
    subtitle = 'Packs observed vs predicted values (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

As you can see, there are some observations with a better fit (a lower prediction error). Let see if we can understand why it is so. Create the following plots and compare them to see what's happening.
```{r log_income_plot, warning = FALSE, message = FALSE}
# Create a ggplot with the prediction_tb. Use the income variable in the x axis
ggplot(predictions_tb, aes(x = income)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = income, xend = income, 
      # Set pack as y and .pred as yend
      y = packs, yend = .pred
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    ) + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = packs, col = 'Observed'), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = .pred, col = 'Predicted'), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  labs(
    x = 'Income (log)',
    y = 'Packs (log)',
    title = 'KNN Results',
    subtitle = 'Consumed packs in function of income (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

```{r training_testing, warning = FALSE, message = FALSE}
# Plot decision boundatires
training = augment(knn_trained, cigarettes_training) %>% 
  mutate(set = 'Training Set')
testing = augment(knn_trained, cigarettes_testing) %>% 
  mutate(set = 'Testing Set')

predictions_tb = bind_rows(training, testing)

ggplot(predictions_tb, aes(x = income)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = income, xend = income, 
      # Set pack as y and .pred as yend
      y = packs, yend = .pred
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    ) + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = packs, shape = 'Observed', col = set), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = .pred, shape = 'Predicted', col = set), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  # Modify shape
  scale_shape_manual(values = c(20,4)) +
  labs(
    x = 'Income (log)',
    y = 'Packs (log)',
    title = 'KNN Results',
    subtitle = 'Consumed packs in function of income (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.85),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm'),
    # Modify the height of the legend key to 0.5 cm
    legend.spacing.y = unit(0.015,'cm')
  ) 

```


