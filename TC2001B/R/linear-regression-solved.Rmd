---
title: "Linear Regression"
author: "MDS. René Rosado González"
output: 
  html_document:
    theme: paper
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

You will work with the `CigarettesSW` dataset from the `AER` package. Fill in the blanks in order to build a k-nearest neighbor regression model.

## Libraries
Load, and install if necessary, the `tidyverse` and `tidymodels` libraries. You will need to have installed the `glmnet` and the `AER` package as well.

```{r libraries, warning = FALSE, message = FALSE}
# Install - load tidyverse                                                       
if(require(tidyverse) == FALSE){                                                
  install.packages('tidyverse')                                                 
  library(tidyverse)                                                            
}else{                                                                          
  library(tidyverse)                                                            
}
# Install - load tidymodels                                                       
if(require(tidymodels) == FALSE){                                                
  install.packages('tidymodels')                                                 
  library(tidymodels)                                                            
}else{                                                                          
  library(tidymodels)                                                            
}
# Install -glmnet                                       
if(require(glmnet) == FALSE){                                                
  install.packages('glmnet')                                                 
}

# Install - AER                                       
if(require(AER) == FALSE){                                                
  install.packages('AER')                                                 
}
```

## Dataset
Load the  `CigarettesB` dataset from the `AER` package. You can read further details about the data using `?CigarettesB`.
```{r data, warning = FALSE, message = FALSE}
# Load the Teachingcigarettes dataset from the AER package
data('CigarettesSW', package = 'AER') 
```

## Exploratory Data Analysis (EDA)
Perform an exploratory data analysis using the `glimpse` and `summary` functions.
```{r glimpse, warning = FALSE, message = FALSE}
## Tidyway
glimpse(CigarettesSW)
```

```{r summary, warning = FALSE, message = FALSE}
# Summary
summary(CigarettesSW)
```
Use the `ggpairs` function from the `GGally` package to create a pairplot with the numeric variables.

```{r ggplot, warning = FALSE, message = FALSE}
# Install - GGally                                       
if(require(GGally) == FALSE){                                                
  install.packages('GGally')                                                 
}

# Pairplot
CigarettesSW %>% 
  # Select only numeric columns
  select_if(is.numeric) %>% 
  GGally::ggpairs()
```
We will need to deflact values to make them comparable. Calculate de `real_price`,`real_local_tax`, `real_sales_tax`and the `real_income_percapita``
```{r data_wrangling}
cigarettes = CigarettesSW %>% 
  # Transmute date
  transmute(
    # Keep state, year and packs
    year, packs,
    # Deflact real values
    real_price = price / cpi,
    real_local_tax =  tax / cpi,
    real_sales_tax =  taxs / cpi,
    real_income_percapita = income / population / cpi
  )
```


## Linear Regression
Create a model specification for the linear regression using the `tidymodels` framework. 
```{r model, warning = FALSE, message = FALSE}
linear_model = linear_reg() %>% 
  # Set the engine
  set_engine("glmnet") %>% 
  # Set the mode
  set_mode('regression') %>% 
  # Set hyperparameters to tune
  set_args(
    penalty = tune(),
    mixture = tune()
    )
```

Make an initial data split with 75% of the observations in the training set. To get consistent results lets set a random seed of `123`.
```{r splitting, warning = FALSE, message = FALSE}
# Data splitting for samples
set.seed(123)
cigarettes_split = initial_split(
  # Data to split
  data = cigarettes,
  # Proportions
  prop = 0.80,
  # Variable of interest
  strata = packs
)

# Get training and testing samples
cigarettes_training = training(cigarettes_split)
cigarettes_testing = testing(cigarettes_split)
```

Create 3 cross validation folds from the training set.
```{r folds, warning = FALSE, message = FALSE}
# Create cross-validation folds
set.seed(123)
cigarettes_folds = vfold_cv(cigarettes_training, v = 3)
```

Create the following recipe to predict the `packs` in function of all other variables.
```{r recipe, warning = FALSE, message = FALSE}
# Create a recipe
recipe = recipe(
  # Set a formula
  formula = packs ~ ., 
  # Set input data
  data = cigarettes_training
) %>% 
  step_log(all_numeric()) %>% 
  step_dummy(year)
```

```{r recipe_check, warning = FALSE, message = FALSE}
# Create a recipe
recipe  %>% 
  prep() %>% 
  juice()
```

Make a workflow object with the recipe and model you just created.
```{r workflow, warning = FALSE, message = FALSE}
# Create a workflow
linear_workflow = workflow() %>% 
  # Add your recipe
  add_recipe(recipe) %>% 
  # Add your model
  add_model(linear_model)
```

Perform hyperparameter tuning on the workflow you just created using a `grid` of size 100.
```{r tuning, warning = FALSE, message = FALSE}
# Get parameters to tune
linear_parameters = linear_workflow %>% 
  extract_parameter_set_dials() 

# Create a tune grid
set.seed(123)
linear_tuning = tune_grid(
  object = linear_workflow,
  resamples = cigarettes_folds,
  param_info = linear_parameters,
  metrics = metric_set(yardstick::rmse),
  control = control_grid(verbose = TRUE),
  grid = 100
  )
```
Collect the tuning metrics and select the best model based on the `rmse` metric.
```{r best_model, warning = FALSE, message = FALSE}
# Collegt metrics
tuning_metrics = linear_tuning %>%
  collect_metrics() %>% 
  # Arrange form higher mean to lower mean
  arrange(mean)

# Select the best model
best_linear = linear_tuning %>%
  select_best("rmse")

# Print the best model
print(best_linear)
```
Finalize your workflow and make the last fit to collect the performance of the model with the testing sample.
```{r finalize, warning = FALSE, message = FALSE}
# Finalize the workflow with the best model
final_linear = linear_workflow %>% 
  finalize_workflow(best_linear)

# Make the last fit
results_linear = final_linear %>% 
  last_fit(
    split = cigarettes_split,
    metrics = metric_set(yardstick::rmse)
    )

# Collect testing metrics
metrics_linear = results_linear %>% 
  collect_metrics()

print(metrics_linear)
```

Plot the regression plot of the model you just trained
```{r regression_plot, warning = FALSE, message = FALSE}
# Extract the trained model
linear_trained = results_linear %>% 
  extract_fit_parsnip()

# Preprocessor
cigarettes_baked = recipe %>% 
  prep() %>% 
  bake(new_data = cigarettes)
# Add predictions
predictions_tb = augment(linear_trained, cigarettes_baked) 

# Regression plot (observed vs predicted)
ggplot(predictions_tb, aes(x = packs, y = .pred)) + 
  # Create a scatter plot
  geom_point(alpha = 0.75) + 
  # Add 45 degree, red, dashhed curve
  geom_abline(linetype = 'dashed') + 
  # Make equal axis coordinates
  coord_obs_pred() +
  # Add proper labels
  labs(
    x = 'Observed',
    y = 'Predicted',
    title = 'linear Results',
    subtitle = 'Packs observed vs predicted values (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

As you can see, there are some observations with a better fit (a lower prediction error). Let see if we can understand why it is so. Create the following plots and compare them to see what's happening.
```{r log_income_plot, warning = FALSE, message = FALSE}
# Create a ggplot with the prediction_tb. Use the income variable in the x axis
ggplot(predictions_tb, aes(x = real_price)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = real_price, xend = real_price, 
      # Set pack as y and .pred as yend
      y = packs, yend = .pred
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    ) + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = packs, col = 'Observed'), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = .pred, col = 'Predicted'), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  labs(
    x = 'Income (log)',
    y = 'Packs (log)',
    title = 'linear Results',
    subtitle = 'Consumed packs in function of income (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.95),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm')
  ) 

```

```{r training_testing, warning = FALSE, message = FALSE}
# Plot decision boundatires
training = recipe %>% 
  prep() %>% 
  juice() %>% 
  augment(x = linear_trained) %>% 
  mutate(set = 'Training Set')
testing = recipe %>% 
  prep() %>% 
  bake(new_data = cigarettes_testing) %>% 
  augment(x = linear_trained) %>% 
  mutate(set = 'Testing Set')

predictions_tb = bind_rows(training, testing)

ggplot(predictions_tb, aes(x = real_price)) +
  # Add a segment line
  geom_segment(
    aes(
      # Set the income variable in the x axis
      x = real_price, xend = real_price, 
      # Set pack as y and .pred as yend
      y = packs, yend = .pred
      ),
    # Set the linetype to dashed
    linetype = 'dashed'
    )  + 
  # Add a scatter plot with the packs variable. Color the dots as 'Observed'
  geom_point(
    aes(y = packs, shape = 'Observed', col = set), 
    alpha = 0.5, size = 2
    ) + 
  # Add a scatter plot with the .pred variable. Color the dots as 'Predicted'
  geom_point(
    aes(y = .pred, shape = 'Predicted', col = set), 
    alpha = 0.5 , size = 2
    ) + 
  # Set color to blue and red
  scale_color_manual(values = c('blue','red')) +
  # Add proper labels
  # Modify shape
  scale_shape_manual(values = c(20,4)) +
  labs(
    x = 'Income (log)',
    y = 'Packs (log)',
    title = 'linear Results',
    subtitle = 'Consumed packs in function of income (log)',
    caption = '@renorosgon'
  ) +
  # Use a default theme
  theme_bw() +
  # Modify legend attributes using legend.attribute
  theme(
     # Delete legend title
    legend.title = element_blank(),
    # Delete legend background
    legend.background = element_blank(),
    # Delete legend box background
    legend.box.background = element_blank(),
    # Make legend key fill transparent
    legend.key = element_rect(fill = "transparent"),
    # Modify the legend position to de coordinates c(0.1, 0.95)
    legend.position = c(0.1, 0.85),
    # Modify the height of the legend key to 0.5 cm
    legend.key.height = unit(0.5,'cm'),
    # Modify the height of the legend key to 0.5 cm
    legend.spacing.y = unit(0.015,'cm')
  ) 

```


